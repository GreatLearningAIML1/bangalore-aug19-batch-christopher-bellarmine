{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kIWaR5ZpKlJ"
   },
   "source": [
    "## Project Ojective - Dog Breed Classification\n",
    "\n",
    "We are provided with a training set and a test set of images of dogs. Each image has a filename that is its unique id. The dataset comprises 120 breeds of dogs. The objective of the project is to create a classifier capable of determining a dog's breed from a photo. We will use traditional CNN with data augmentation and Transfer Learning by VGG16 model with weights pre-trained on Imagenet for calssification of the dog breed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7MDmaAw2xGO"
   },
   "source": [
    "### Load Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scipy.misc\n",
    "from scipy.stats import itemfreq\n",
    "from random import sample\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Dense, Activation, Dropout, Flatten, Reshape\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Image manipulation\n",
    "import PIL.Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Open a Zip File\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Uik_q4F9gNKj",
    "outputId": "52a825e7-b951-4a32-a558-d8391cd0f0d8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1q2zzIaUprk_"
   },
   "source": [
    "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tp6FvAToxUFs",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_path = \"dogImages/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rydR_j8lqUei"
   },
   "source": [
    "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3350WZM4w4EL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with ZipFile(project_path+'train.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NHq1iBCfFjE"
   },
   "source": [
    "Repeat the same step for test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fxzynvB2YCb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with ZipFile(project_path+'test.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jnUMhQrDfJmz"
   },
   "source": [
    "Repeat the same step for sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PyTxE8q2jLf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2G9RIxB-fOLT"
   },
   "source": [
    "Repeat the same step for labels.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXtnEoEixbgi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with ZipFile(project_path+'labels.csv.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJc1lVrW_jmL"
   },
   "source": [
    "We now have 4 files - Train folder, test folder and labels.csv and sample_submission.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYmJKmDqqpng"
   },
   "source": [
    "### Read labels.csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmlJ2VMY96IZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(project_path+'labels.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "hPvb1RSc96If",
    "outputId": "c9c8e413-60ab-4637-acf4-fb624cefbde0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q4JNa9ezgeQe",
    "outputId": "49f01358-ee38-4e8a-e6df-83ce453fb65d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP8YAzQvqyK-"
   },
   "source": [
    "### Print the count of each category of Dogs given in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3L2naXlr96Im",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "breed_count = labels['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "CLm3W5RN96Ir",
    "outputId": "02f657f9-7eca-4dd3-f389-456cdff37722",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "breed_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a7q4H7IrHa4a",
    "outputId": "b202891d-41cc-4527-a118-7bd9b56c7418",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "breed_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WI94_Qcc0D4M"
   },
   "source": [
    "### Get one-hot encodings of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q48iAcY196I3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets = pd.Series(labels['breed'])\n",
    "one_hot = pd.get_dummies(targets, sparse=True)\n",
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "9nlWmRNM96I8",
    "outputId": "d86cbc26-8d86-47f1-9376-e28b2813299f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWaJ9naXfoiU"
   },
   "source": [
    "## Preparing training dataset\n",
    "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
    "2. Create 2 variables <br> \n",
    "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
    "     b.  y_train - Corresponding label of the dog <br>\n",
    "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
    "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aC2f9ecR0XGR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rows = 128\n",
    "img_col = 128 \n",
    "img_channel = 1\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RWotLGwrKDwi",
    "outputId": "d6f46df2-8cf5-4981-d91f-a34289bd5c5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for id,breed in tqdm(labels.values):\n",
    "  train_img = cv2.imread('./train/{}.jpg'.format(id),1)\n",
    "  train_img_resize = cv2.resize(train_img, (img_rows,img_col))\n",
    "  x_train.append(train_img_resize)\n",
    "  y_train.append(breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AteE8UriahvP",
    "outputId": "ad43bb79-9cb9-4451-edae-a1505f138ea3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nkkZEpOe0ipk",
    "outputId": "6f460cb6-4aba-4a01-859d-bcc359dd7f22",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "pHkJsS3JLcDS",
    "outputId": "b7313b24-068a-4d7e-ef9b-5bf0473e6e0d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image =x_train[0]\n",
    "\n",
    "im2 = image.copy()\n",
    "im2[:, :, 0] = image[:, :, 2]\n",
    "im2[:, :, 2] = image[:, :, 0]\n",
    "plt.imshow(im2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "FAcP3ys5Cx7o",
    "outputId": "e76182b8-eeea-4e92-dd94-de7734c333e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    random_index = random.randint(0, 10221)\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(x_train[random_index][:,:,::-1])\n",
    "    plt.title(y_train[random_index])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ioWDEgElBOs"
   },
   "source": [
    "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NheIxQw_4F0Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train, sparse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8g4A_wrasnO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hR1bcJ5Dxh0t",
    "outputId": "1bbd675e-058f-47f7-e360-6e79f7062b01",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UxPs7TUlbYOJ",
    "outputId": "b60e302e-7edb-4ca4-c94e-6b5457a35abd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CNc-XJV1q5D7",
    "outputId": "9a1ddb4f-1ad3-4057-f757-9a487e3ebcc3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Z5ehA--dH-y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "x_train /= 255\n",
    "#y_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "SN66Oez9g4yR",
    "outputId": "48d146b1-d520-42b0-cc3c-e369ecaebbbe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdCXuAE11gZL"
   },
   "source": [
    "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YugtFMU248Kz",
    "outputId": "82baf2dd-c01d-429a-e7d6-113997e91766",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n",
    "print (len(x_train2))\n",
    "print (len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gDD6Ye3h4_0z",
    "outputId": "b114f200-1556-41e7-d07a-110c78984f15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTlawBSy5C_g",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train2 = x_train2.reshape(x_train2.shape[0],128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AirtjYSN5DEu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_val = x_val.reshape(x_val.shape[0],128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "kpWx-pgV96Jv",
    "outputId": "8e6b8a7d-2b0f-4ad8-fd71-edb431dbacea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (x_train2.shape)\n",
    "print (x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XfMJeZsE5X9t",
    "outputId": "cdd100cf-e94f-4ca7-f722-16399837d1f4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_train2.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "rPLRhxVmV9CZ",
    "outputId": "fc07d0d6-dadf-4225-fa07-87c93aff5559",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "xTD_3laiw0vm",
    "outputId": "0dbaa803-cbf8-454d-add1-bb9b71665c58",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image =x_train2[0]\n",
    "\n",
    "im2 = image.copy()\n",
    "im2[:, :, 0] = image[:, :, 2]\n",
    "im2[:, :, 2] = image[:, :, 0]\n",
    "plt.imshow(im2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkL-N1jDsU8m"
   },
   "source": [
    "### Loading the test data\n",
    "Read the id column from the samples_submission.csv and store it in test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "actIggCq6VLr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv(project_path+'sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "isiHYn3OG948",
    "outputId": "5b356759-cd11-4b91-b1e6-c3909bf89553",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnpXdpd9b3E7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_img=sample_submission['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XUvVzIFshIEE",
    "outputId": "48ad8815-b2c9-40fc-e13d-dde0b45181ed",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "NbhWzZhd69na",
    "outputId": "ad18b0de-dae6-4c08-d8fe-a595fc365b07",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_img.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEJqZIMbm0Jo"
   },
   "source": [
    "Run the below code to load the test image files in x_test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zf7n4WG-b3Hv",
    "outputId": "74c2a439-07d3-4a43-acf1-747b22a65df5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rows = 128\n",
    "img_col = 128 \n",
    "img_channel = 1\n",
    "\n",
    "x_test_feature = []\n",
    "\n",
    "i = 0 # initialisation\n",
    "for f in tqdm(test_img.values): # f for format ,jpg\n",
    "    img = cv2.imread('./test/{}.jpg'.format(f), 1)\n",
    "    img_resize = cv2.resize(img, (img_rows, img_col)) \n",
    "    x_test_feature.append(img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tltj5bDpILWl",
    "outputId": "1eaad0bd-bd37-4e62-9274-98614d055d5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test_feature[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9My6qSyDnE-_"
   },
   "source": [
    "Normalize the test data and convert it into 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKKNVMLRhwRA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_test = np.array(x_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flNQVcOviGZA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OzHDBb3lHHzz",
    "outputId": "83268ab6-6791-43c9-ddc6-0e18d957bfe0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93n-IntMnJGI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(x_test.shape[0],128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q1wXRxLOAeeg",
    "outputId": "9a54a8bd-f8a7-4757-f10c-82556746637a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "TiycGuLhivnj",
    "outputId": "9442ad4d-407b-4b9c-c26a-a8ea8a2c83bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image =x_test[0]\n",
    "\n",
    "im2 = image.copy()\n",
    "im2[:, :, 0] = image[:, :, 2]\n",
    "im2[:, :, 2] = image[:, :, 0]\n",
    "plt.imshow(im2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "ya08lMQ5bvop",
    "outputId": "205bcddf-0b06-4dbc-ecc6-875fb91ba286",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    random_index = random.randint(0, 10221)\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(x_test[random_index][:,:,::-1])\n",
    "    plt.title(test_img[random_index])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Tnr59VEjHKk"
   },
   "source": [
    "Note: x_test and corresponding label IDs will not be used instead the train and val data will be used for model building and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKezNJVMsocP"
   },
   "source": [
    "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
    "\n",
    "1. Add a Dense layer with 256 neurons with `relu` activation\n",
    "\n",
    "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2jxTY2S96J4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "   \n",
    "# 1st CNN Layer\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Convolution2D(32,5, 5, input_shape=(128, 128, 3)))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 2nd CNN Layer\n",
    "\n",
    "model.add(Convolution2D(32,3, 3, input_shape=(128, 128, 3)))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Prediction Layer\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store Training Results\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "f_BAvCzo96J6",
    "outputId": "47ce6846-ad06-4c1a-8422-40ac5893e218",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x_train2, y_train2, batch_size=10, nb_epoch=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ui8EXw6_oqpR"
   },
   "source": [
    "### Use batch_size = 128 and epochs = 50 and execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IriIc37NozbK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0PR9j5_Xozmd",
    "outputId": "d09b29ad-df34-46e4-a5bc-903de7420507",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train2, y_train2,epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8hWaKmjoz69"
   },
   "source": [
    "Poor Model Accuracy even after 50 epochs..!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agJKkc6xtKiq"
   },
   "source": [
    "### Use Data Augmentation in the above model to see if the accuracy improves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31Mn8qnZb3Ru",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sssbaTfxlkk"
   },
   "source": [
    "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
    "\n",
    "You need to use train_datagen.flow() and val_datagen.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "sehaRgT-96KQ",
    "outputId": "0d525acf-4e12-40bd-a990-da3f92ba4790",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "train_generator = datagen.flow(x_train2[:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(train_generator.next().squeeze(), cmap='Blues')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "17Ijrc7lclUE",
    "outputId": "1c961836-a45e-459c-fac4-41e3fd23f7ea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "val_generator = datagen.flow(x_val[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(val_generator.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVFQJZw3x4-C"
   },
   "source": [
    "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "eFvvlIf7nEP4",
    "outputId": "aa8e6728-dbd3-425d-95b1-c86481ae9ec0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history =model.fit(datagen.flow(x_train2, y_train2,batch_size=1), steps_per_epoch=x_train2.shape[0], epochs=10, validation_data=(x_val, y_val), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2zmLztqo5DY"
   },
   "source": [
    "Model accuracy is still very poor!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSTATrhsAo7L"
   },
   "source": [
    "### Lets use Transfer Learning\n",
    "\n",
    "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zy5JdbW6pIvD"
   },
   "source": [
    "Use the below code to load VGG16 weights trained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrqs0zg7ApNw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# Instantiate the model with the pre-trained weights (no top)\n",
    "base_model= VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
    "                 include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EItOlRBGpV_A"
   },
   "source": [
    "Print the summary of the base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "lQsEBgnlpHjH",
    "outputId": "6321c7e2-c63a-42f7-8c45-2dfe9e36b16b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHpeOyW0qauW"
   },
   "source": [
    "### Add the following classification layers to the imported VGG Model <br>\n",
    "1. Flatten Layer\n",
    "2. Dense layer with 1024 neurons with activation as Relu\n",
    "3. Dense layer with 256 neurons with activation as Relu\n",
    "4. Dense layer with 120 neurons with activation as Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BpT4MLkqoaO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling3D\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "# let's add two fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# and a softmax layer for 120 classes\n",
    "predictions = Dense(120, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fHZPoU0mzdtd",
    "outputId": "ac4bd0e0-d92e-4ae3-ff2c-37b962fa02e9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeQem0pHITIj"
   },
   "source": [
    "### Make all the layers in the base_model (VGG16) to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "C7w9CSPvIRnX",
    "outputId": "153e24fb-6cd1-4b04-b9b6-9a6a4aa4d147",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "  #if('conv' in layer.name): #prefix detection to freeze layers which does not have dense\n",
    "    #Freezing a layer\n",
    "    layer.trainable = False\n",
    "\n",
    "#Module to print colourful statements\n",
    "from termcolor import colored\n",
    "\n",
    "#Check which layers have been frozen \n",
    "for layer in base_model.layers:\n",
    "  print (colored(layer.name, 'blue'))\n",
    "  print (colored(layer.trainable, 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj-BwqgfIkdv"
   },
   "source": [
    "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWsBGCPlALgk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YD5fAgVQIpKZ"
   },
   "source": [
    "Try to get training and validation accuracy to be more than 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "SZk2SWvjIoRP",
    "outputId": "f3c638cb-f9dd-4119-e29a-2a3d9bf63a40",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train2, y_train2,epochs=10, batch_size=128, verbose=1,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "N8Mic6x9A7Bs",
    "outputId": "ceb2fc9a-f9ef-460b-fe90-ca6fc0ca3ad6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_acc_loss(history):\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    " \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    " \n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybMxKQd0BfrF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "predictions = np.argmax(model.predict(x_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iUAAdCJpfsGS",
    "outputId": "768419a2-3e80-4280-d40f-9d4119e34c3d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "y3cs3KHprzFB",
    "outputId": "d4b31d49-15a3-448f-9c7c-62590769b91c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmP5ydg_sd6w",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val_label=np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q_khXv5UsnHG",
    "outputId": "687ff69b-01ac-4c7f-b7b6-2dc4383c016b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "5XaaoGnyfqgN",
    "outputId": "09570bf8-bcb0-4938-e545-c20f21cf0a37",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nAccuracy on Test Data: \", accuracy_score(y_val_label, predictions))\n",
    "print(\"\\nNumber of correctly identified images: \",\n",
    "      accuracy_score(y_val_label, predictions, normalize=False),\"\\n\")\n",
    "confusion_matrix(y_val_label, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3xbs-4Ka4K_"
   },
   "source": [
    "Leveraging VGG16 Network to see if the accuracy score improves ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnrKCsd0a0qb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# Creating a checkpointer \n",
    "checkpointer = ModelCheckpoint(filepath=(project_path+'vgg16_weights_full_model.h5'), \n",
    "                               verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "nVlZXxnka1_E",
    "outputId": "e2f2c662-9b49-49c4-bc96-9737e8f79fc3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the VGG16 network \n",
    "print(\"[INFO loading network...\")\n",
    "model_vgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=x_train.shape[1:])\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "72D66NdVa8yr",
    "outputId": "91ab3b97-d30f-443a-d74d-53ad057ce05c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, Flatten, GlobalAveragePooling2D\n",
    "model_transfer_full = Sequential()\n",
    "model_transfer_full.add(model_vgg)\n",
    "model_transfer_full.add(GlobalAveragePooling2D())\n",
    "model_transfer_full.add(Dropout(0.2))\n",
    "model_transfer_full.add(Dense(1024, activation='relu'))\n",
    "model_transfer_full.add(Dense(256, activation='relu'))\n",
    "model_transfer_full.add(Dense(120, activation='softmax'))\n",
    "model_transfer_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_1qlG70IbAfl",
    "outputId": "1ecf2842-9735-43e1-c170-4342b9c04968",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00001)\n",
    "model_transfer_full.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "history = model_transfer_full.fit(x_train2, y_train2, batch_size=32, epochs=30,\n",
    "          validation_data=(x_val, y_val),callbacks=[checkpointer],verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suxAiUqqf4lt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "predictions = np.argmax(model_transfer_full.predict(x_val), axis=1)\n",
    "y_val_label=np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "JNU1RcW0f6uU",
    "outputId": "647d4c4b-541e-4e79-9a98-6ae206e49635",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nAccuracy on Test Data: \", accuracy_score(y_val_label, predictions))\n",
    "print(\"\\nNumber of correctly identified images: \",\n",
    "      accuracy_score(y_val_label, predictions, normalize=False),\"\\n\")\n",
    "confusion_matrix(y_val_label, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAystwGggP3H"
   },
   "source": [
    "Due to memory limitations, a small subset of the data (256/10221) is taken and operated on which leads to low accuracy levels (1%). On using transfer learning with VGG we obtain an accuracy level of 2-3 %."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Dog_Breed_KK_CV_Project2_Classification_Ver 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
